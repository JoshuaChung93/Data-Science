{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d588fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30강 - 이미지 연산\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"pencils.webp\")\n",
    "number1 = np.ones_like(src) * 127\n",
    "number2 = np.ones_like(src) * 2\n",
    "\n",
    "add = cv2.add(src, number1)\n",
    "sub = cv2.subtract(src, number1)\n",
    "mul = cv2.multiply(src, number2)\n",
    "div = cv2.divide(src, number2)\n",
    "\n",
    "src = np.concatenate((src, src, src, src), axis = 1)\n",
    "number = np.concatenate((number1, number1, number2, number2), axis = 1)\n",
    "dst = np.concatenate((add, sub, mul, div), axis = 1)\n",
    "\n",
    "dst = np.concatenate((src, number, dst), axis = 0)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8b1d38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m div \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdivide(src, number2)\n\u001b[0;32m     13\u001b[0m src \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([src, src, src, src], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m number \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumber1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m dst \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([add, sub, mul, div], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m dst \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([src, number, dst], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "# 30강 - 이미지 연산... 다른 방법\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"pencils.webp\")\n",
    "number1 = 127 ## np.ones_like(src) * 127\n",
    "number2 = 2   ## np.ones_like(src) * 2\n",
    "\n",
    "add = cv2.add(src, number1)\n",
    "sub = cv2.subtract(src, number1)\n",
    "mul = cv2.multiply(src, number2)\n",
    "div = cv2.divide(src, number2)\n",
    "\n",
    "src = np.concatenate([src, src, src, src], axis = 1)\n",
    "number = np.concatenate([number1, number1, number2, number2], axis = 1)\n",
    "dst = np.concatenate([add, sub, mul, div], axis = 1)\n",
    "\n",
    "dst = np.concatenate([src, number, dst], axis = 0)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7412bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31강 - 이미지 연산(2)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('pencils.webp')\n",
    "src = cv2.resize(src, dsize=(320, 240), interpolation=cv2.INTER_AREA) # 원본 이미지 크기 축소\n",
    "number = np.ones_like(src) * 127 # 연산 이미지로 회색 이미지 (127,127,127)을 사용\n",
    "\n",
    "_max = cv2.max(src, number) # 이미지 연산 진행. 최댓값\n",
    "_min = cv2.min(src, number) # 최솟값\n",
    "_abs = cv2.absdiff(src, number) # 절댓값 차이. 연산 진행후 값이 마이너스여도 양수 형태로 반환함\n",
    "compare = cv2.compare(src, number, cv2.CMP_GT) # 비교. True 일 경우 255, False일 경우 0으로 변경\n",
    "\n",
    "src = np.concatenate((src,src,src,src), axis = 1) # 연결 함수로 이미지 연결\n",
    "number = np.concatenate((number,number,number,number), axis =1)\n",
    "dst = np.concatenate((_max,_min,_abs,compare), axis = 1)\n",
    "\n",
    "dst = np.concatenate((src,number,dst), axis =0)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34048bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32강 - 비트 연산\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('analysis.webp')\n",
    "src = cv2.resize(src, dsize=(320, 240), interpolation=cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # 이진화 선언, 임계값 127\n",
    "\n",
    "_and = cv2.bitwise_and(gray, binary) # 논리곱\n",
    "_or = cv2.bitwise_or(gray, binary) # 논리합\n",
    "_xor = cv2.bitwise_xor(gray, binary) # 배타적 논리합\n",
    "_not = cv2.bitwise_not(gray) # 부정\n",
    "\n",
    "src = np.concatenate((np.zeros_like(gray), gray, binary, np.zeros_like(gray)), axis=1)\n",
    "dst = np.concatenate((_and, _or, _xor, _not), axis=1)\n",
    "dst = np.concatenate((src,dst), axis=0)\n",
    "\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79c2a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33강 - 히스토그램\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread('road.webp')\n",
    "src = cv2.resize(src, dsize=(720, 480), interpolation=cv2.INTER_AREA) # 크기 축소\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "result = np.zeros((src.shape[0], 256), dtype=np.uint8) # 히스토그램 이미지 선언. n개의 개수를 갖는 256분포로 이미지 사용. 높이는 원본 이미지, 넓이는 256 사용\n",
    "\n",
    "# cv2.calcHist(연산 이미지, 특정 채널, 마스크, 히스토그램 크기, 히스토그램 범위)\n",
    "hist = cv2.calcHist([gray], [0], None, [256], [0,256]) # 히스토그램 계산 함수를 통해 분포 계산\n",
    "# cv2.normalize(입력 배열, 결과 배열, alpha, beta, 정규화 기준)\n",
    "cv2.normalize(hist, hist, 0, result.shape[0], cv2.NORM_MINMAX) # 정규화 함수를 통해 값을 변경\n",
    "\n",
    "# gray 와 result는 이미지 높이가 같으므로 병합 함수(np.hstack)로 이미지를 연결\n",
    "for x, y in enumerate(hist):\n",
    "    cv2.line(result, (int(x), result.shape[0]), (int(x), result.shape[0] - int(y)), 255)\n",
    "    \n",
    "dst = np.hstack([gray, result])\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "85\n",
      "[85  0 85]\n"
     ]
    }
   ],
   "source": [
    "# 34강 - 픽셀 접근\n",
    "# 회색 그라데이션 이미지인 gray 선언. numpy.linspace를 활용해 구현. 이미지 배열이 아니므로 차원 변경 np.reshape 함수를 활용해 단일 채널 이미지로 변경\n",
    "gray = np.linspace(0, 255, num=90000, endpoint=True, retstep=False, dtype=np.uint8).reshape(300,300,1)\n",
    "# 색상 그라데이션 이미지인 color를 선언\n",
    "color = np.zeros((300,300,3), np.uint8)\n",
    "color[0:150, :, 0] = gray[0:150, :, 0]\n",
    "color[:, 150:300, 2] = gray[:, 150:300, 0]\n",
    "# 행, 열, 차원 구조로 배열 접근. 만약 차원을 포함하지 않는 경우 numpy배열 형식의 값 반환.\n",
    "x, y, c = 200, 100, 0\n",
    "access_gray = gray[y,x,c]\n",
    "access_color_blue = color[y,x,c]\n",
    "access_color = color[y,x]\n",
    "\n",
    "print(access_gray, access_color_blue, access_color, sep='\\n')\n",
    "\n",
    "cv2.imshow('gray',gray)\n",
    "cv2.imshow('color',color)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35강 - 트랙 바\n",
    "import cv2\n",
    "\n",
    "def onChange(pos):\n",
    "    pass\n",
    "# 원본 이미지 선언, 그레이스케일 적용\n",
    "src = cv2.imread(\"cherryblossom.webp\", cv2.IMREAD_GRAYSCALE)\n",
    "# 윈도우 창 제목과 윈도우 창 생성. 윈도우 창 제목은 변수로 기능\n",
    "cv2.namedWindow('Trackbar Windows')\n",
    "# 트랙 바 생성. cv2.createTrackbar('트랙 바 이름', '윈도우 창 제목', 최솟값, 최댓값, 콜백 함수)) onChange함수의 pos는 현재 발생한 트랙 바 값을 반환,\n",
    "cv2.createTrackbar('threshold', 'Trackbar Windows', 0, 255, onChange)\n",
    "cv2.createTrackbar('maxValue', 'Trackbar Windows', 0, 255, lambda x : x)\n",
    "# 트랙 바 값 설정. cv2.setTrackbaPos('트랙 바 이름', '윈도우 창 제목', 설정값) 초기값 할당\n",
    "cv2.setTrackbarPos('threshold', 'Trackbar Windows', 127)\n",
    "cv2.setTrackbarPos('maxValue', 'Trackbar Windows', 255)\n",
    "# 반복문 사용해 지속적으로 화면 갱신. 1ms마다 키보드 이벤트 감시\n",
    "while cv2.waitKey(1) != ord('q'):\n",
    "    \n",
    "    thresh = cv2.getTrackbarPos('threshold', 'Trackbar Windows')\n",
    "    maxval = cv2.getTrackbarPos('maxValue', 'Trackbar Windows')\n",
    "    \n",
    "    _, binary = cv2.threshold(src, thresh, maxval, cv2.THRESH_BINARY) # 원본 이미지 이진화 진행. 문턱값 thresh, 최대값 maxval\n",
    "    \n",
    "    cv2.imshow('Trackbar Windows', binary)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef05eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36강 - 적응형 이진화\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('tree.webp')\n",
    "src = cv2.resize(src, dsize=(720, 480), interpolation=cv2.INTER_AREA) # 크기 축소\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "# adaptiveThreshold(입력 이미지, 최댓값, 적응형 이진화 플래그, 임곗값 형식, 블록 크기, 감산값)\n",
    "binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 467, 37) # 그레이스케일 이미지 이진화 적용 \n",
    "\n",
    "cv2.imshow('binary',binary)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "420466d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37강 - 템플릿 매칭\n",
    "import cv2\n",
    "# 원본 이미지와 템플릿 이미지 선언\n",
    "src = cv2.imread(\"hat.webp\", cv2.IMREAD_GRAYSCALE)\n",
    "templit = cv2.imread(\"hat2.webp\", cv2.IMREAD_GRAYSCALE)\n",
    "# 결과 이미지 선언\n",
    "dst = cv2.imread(\"hat.webp\")\n",
    "# 템플릿 매칭 적용. cv2.matchTemplate(원본, 템플릿, 템플릿 매칭 플래그)\n",
    "result = cv2.matchTemplate(src, templit, cv2.TM_SQDIFF_NORMED)\n",
    "# 최소/최대 위치 함수(cv2.minMaxLoc)로 검출값 찾기\n",
    "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(result)\n",
    "x, y = minLoc\n",
    "h, w = templit.shape\n",
    "# 검출된 이미지 결과 이미지(dst)위에 표시\n",
    "dst = cv2.rectangle(dst, (x, y), (x +  w, y + h) , (0, 0, 255), 1)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab027cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 38강 - ORB(Oriented FAST and rotated BRIEF)알고리즘\n",
    "import cv2\n",
    "import numpy as np\n",
    "# 원본 이미지와 타겟 이미지 선언\n",
    "src = cv2.imread('apple_books.webp')\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "target = cv2.imread('apple.webp', cv2.IMREAD_GRAYSCALE)\n",
    "# orb클래스로 orb 객체 생성\n",
    "orb = cv2.ORB_create(\n",
    "    nfeatures=40000,\n",
    "    scaleFactor=1.2,\n",
    "    nlevels=8,\n",
    "    edgeThreshold=31,\n",
    "    firstLevel=0,\n",
    "    WTA_K=2,\n",
    "    scoreType=cv2.ORB_HARRIS_SCORE, # 점수 방식으로 해리스 코너 방식 적용 / cv.ORB_FAST_SCORE 방식도 가능\n",
    "    patchSize=31,\n",
    "    fastThreshold=20,\n",
    ")\n",
    "# 각각의 이미지에 특징점 및 기술자 계산 매서드를 사용해 특징점과 기술자 계산 orb.detectAndCompute(이미지, 마스크)\n",
    "kp1, des1 = orb.detectAndCompute(gray, None)\n",
    "kp2, des2 = orb.detectAndCompute(target, None)\n",
    "# 전수 조사 매칭을 활용해 객채 인식 및 추출\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "# 매치 함수로 최적의 매칭 검출. bf.match(기술자1, 기술자2)\n",
    "matches = bf.match(des1,des2)\n",
    "# 거리는 특징점 간 유클리드 거리 또는 매칭의 품질을 의미. distance값이 낮을수록 매칭이 정확함. sort함수로 distance 값이 낮은 순으로 정렬\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "# 반복문을 통해 우수한 상위 100개에 대해서만 표시\n",
    "for i in matches[:100]:\n",
    "    idx = i.queryIdx\n",
    "    x1, y1 = kp1[idx].pt\n",
    "    cv2.circle(src, (int(x1), int(y1)), 3, (255,0,0), 3)\n",
    "    \n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e5e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
