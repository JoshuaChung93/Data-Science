{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshuaChung93/Data-Science/blob/main/Computer_Vision_Masterclass_Face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DeXKmcjLl89"
      },
      "source": [
        "# Computer Vision Masterclass - Face recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgQKD4_BSOPP"
      },
      "source": [
        "## OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8zOtNhKLp-Z"
      },
      "source": [
        "### Loading the dataset\n",
        "\n",
        "- Yale faces database: http://vision.ucsd.edu/content/yale-face-database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta2EHPg1-0Gn",
        "outputId": "4ee87914-fd63-409e-c927-45c388a7c7bd"
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM29c2T7_e5V"
      },
      "source": [
        "import zipfile\n",
        "path = '/content/drive/MyDrive/Computer Vision Masterclass/Datasets/yalefaces.zip'\n",
        "zip_object = zipfile.ZipFile(file=path, mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k3yuCEM06FJ"
      },
      "source": [
        "### Pre-processing the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TKNpS9sB-rU",
        "outputId": "30d6ac95-3828-41e3-cfb2-7ebd56623836"
      },
      "source": [
        "import os\n",
        "print(os.listdir('/content/yalefaces/train'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['subject05.rightlight.gif', 'subject15.centerlight.gif', 'subject09.surprised.gif', 'subject11.rightlight.gif', 'subject06.surprised.gif', 'subject13.noglasses.gif', 'subject02.rightlight.gif', 'subject03.sad.gif', 'subject07.glasses.gif', 'subject11.surprised.gif', 'subject15.surprised.gif', 'subject09.noglasses.gif', 'subject10.happy.gif', 'subject02.normal.gif', 'subject04.wink.gif', 'subject07.sleepy.gif', 'subject03.wink.gif', 'subject07.rightlight.gif', 'subject02.noglasses.gif', 'subject08.noglasses.gif', 'subject01.noglasses.gif', 'subject10.surprised.gif', 'subject01.sad.gif', 'subject04.happy.gif', 'subject06.glasses.gif', 'subject14.surprised.gif', 'subject13.centerlight.gif', 'subject15.noglasses.gif', 'subject03.happy.gif', 'subject12.noglasses.gif', 'subject10.leftlight.gif', 'subject07.centerlight.gif', 'subject05.noglasses.gif', 'subject12.glasses.gif', 'subject14.leftlight.gif', 'subject04.sad.gif', 'subject13.wink.gif', 'subject04.glasses.gif', 'subject11.sleepy.gif', 'subject09.sleepy.gif', 'subject02.sad.gif', 'subject13.rightlight.gif', 'subject11.leftlight.gif', 'subject01.surprised.gif', 'subject12.sad.gif', 'subject15.happy.gif', 'subject02.glasses.gif', 'subject01.normal.gif', 'subject01.rightlight.gif', 'subject14.happy.gif', 'subject05.happy.gif', 'subject02.wink.gif', 'subject06.sleepy.gif', 'subject02.surprised.gif', 'subject10.wink.gif', 'subject05.wink.gif', 'subject06.centerlight.gif', 'subject04.sleepy.gif', 'subject05.leftlight.gif', 'subject08.sad.gif', 'subject01.glasses.gif', 'subject06.wink.gif', 'subject04.rightlight.gif', 'subject15.wink.gif', 'subject06.noglasses.gif', 'subject08.happy.gif', 'subject03.surprised.gif', 'subject15.normal.gif', 'subject09.happy.gif', 'subject06.rightlight.gif', 'subject02.sleepy.gif', 'subject15.leftlight.gif', 'subject11.noglasses.gif', 'subject03.sleepy.gif', 'subject12.surprised.gif', 'subject06.normal.gif', 'subject08.sleepy.gif', 'subject04.centerlight.gif', 'subject13.leftlight.gif', 'subject07.normal.gif', 'subject12.centerlight.gif', 'subject08.surprised.gif', 'subject11.wink.gif', 'subject03.noglasses.gif', 'subject14.noglasses.gif', 'subject03.normal.gif', 'subject07.surprised.gif', 'subject09.centerlight.gif', 'subject05.normal.gif', 'subject14.centerlight.gif', 'subject14.wink.gif', 'subject14.sleepy.gif', 'subject07.sad.gif', 'subject12.happy.gif', 'subject14.glasses.gif', 'subject09.glasses.gif', 'subject13.glasses.gif', 'subject04.normal.gif', 'subject08.wink.gif', 'subject01.leftlight.gif', 'subject12.leftlight.gif', 'subject01.wink.gif', 'subject09.wink.gif', 'subject07.noglasses.gif', 'subject14.rightlight.gif', 'subject03.centerlight.gif', 'subject08.leftlight.gif', 'subject09.leftlight.gif', 'subject15.glasses.gif', 'subject11.sad.gif', 'subject09.normal.gif', 'subject10.rightlight.gif', 'subject10.glasses.gif', 'subject12.sleepy.gif', 'subject11.normal.gif', 'subject10.noglasses.gif', 'subject05.sad.gif', 'subject08.glasses.gif', 'subject13.surprised.gif', 'subject13.happy.gif', 'subject10.sleepy.gif', 'subject01.sleepy.gif', 'subject08.centerlight.gif', 'subject05.centerlight.gif', 'subject06.sad.gif', 'subject05.glasses.gif', 'subject03.rightlight.gif', 'subject15.sleepy.gif', 'subject12.wink.gif', 'subject07.wink.gif', 'subject02.happy.gif', 'subject10.normal.gif', 'subject13.normal.gif', 'subject04.noglasses.gif', 'subject11.centerlight.gif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_6MUlv2Cfvg"
      },
      "source": [
        "def get_image_data():\n",
        "  paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]\n",
        "  #print(paths)\n",
        "  faces = []\n",
        "  ids = []\n",
        "  for path in paths:\n",
        "    #print(path)\n",
        "    image = Image.open(path).convert('L')\n",
        "    #print(type(image))\n",
        "    image_np = np.array(image, 'uint8')\n",
        "    #print(type(image_np))\n",
        "    id = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))\n",
        "    #print(id)\n",
        "    ids.append(id)\n",
        "    faces.append(image_np)\n",
        "\n",
        "  return np.array(ids), faces"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kjNb0PaC6-2"
      },
      "source": [
        "ids, faces = get_image_data()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1SKHBy2GFzl",
        "outputId": "5d277d1b-d54a-40ea-c662-ee9c5942b269"
      },
      "source": [
        "ids"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5, 15,  9, 11,  6, 13,  2,  3,  7, 11, 15,  9, 10,  2,  4,  7,  3,\n",
              "        7,  2,  8,  1, 10,  1,  4,  6, 14, 13, 15,  3, 12, 10,  7,  5, 12,\n",
              "       14,  4, 13,  4, 11,  9,  2, 13, 11,  1, 12, 15,  2,  1,  1, 14,  5,\n",
              "        2,  6,  2, 10,  5,  6,  4,  5,  8,  1,  6,  4, 15,  6,  8,  3, 15,\n",
              "        9,  6,  2, 15, 11,  3, 12,  6,  8,  4, 13,  7, 12,  8, 11,  3, 14,\n",
              "        3,  7,  9,  5, 14, 14, 14,  7, 12, 14,  9, 13,  4,  8,  1, 12,  1,\n",
              "        9,  7, 14,  3,  8,  9, 15, 11,  9, 10, 10, 12, 11, 10,  5,  8, 13,\n",
              "       13, 10,  1,  8,  5,  6,  5,  3, 15, 12,  7,  2, 10, 13,  4, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhlCn9pZGJJE",
        "outputId": "dc5f6bf6-aaf5-4adb-ad25-7b4661f8eb8a"
      },
      "source": [
        "len(ids)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUjgMXjmGb7d",
        "outputId": "182f7b25-cd42-44a1-c96d-8a060c96e60f"
      },
      "source": [
        "len(faces)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvF2_Tv_GMBH",
        "outputId": "df034578-a70a-40cb-9a3a-688cecf2a98c"
      },
      "source": [
        "faces[0], faces[0].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 55,  68,  75, ..., 196, 181, 210],\n",
              "        [130, 156, 170, ..., 183, 188, 210],\n",
              "        [130, 131, 146, ..., 203, 195, 200],\n",
              "        ...,\n",
              "        [ 33,  33,  33, ..., 112, 109, 111],\n",
              "        [ 34,  34,  34, ..., 118, 115, 118],\n",
              "        [ 68,  68,  68, ...,  68,  68,  68]], dtype=uint8), (243, 320))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl-JouHAGwbE",
        "outputId": "b16cb25f-b823-4d54-8937-0819a6717cef"
      },
      "source": [
        "243 * 320"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77760"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRuJuHRLvcmW"
      },
      "source": [
        "### Training the LBPH classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP_bE2tWLSz4",
        "outputId": "76295587-d3f3-4a61-b1d7-8ebd80da897a"
      },
      "source": [
        "8 * 8"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTHLAAnTLBfY"
      },
      "source": [
        "# threshold: 1.7976931348623157e+308\n",
        "# radius: 1\n",
        "# neighbors: 8\n",
        "# grid_x: 8\n",
        "# grid_y: 8\n",
        "\n",
        "lbph_classifier = cv2.face.LBPHFaceRecognizer_create(radius = 4, neighbors=14, grid_x = 9, grid_y = 9)\n",
        "lbph_classifier.train(faces, ids)\n",
        "lbph_classifier.write('lbph_classifier.yml')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37itAmjd1AGm"
      },
      "source": [
        "### Recognizing faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ3srgyaMeUs"
      },
      "source": [
        "lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_face_classifier.read('/content/lbph_classifier.yml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUcev8JwMyrx"
      },
      "source": [
        "test_image = '/content/yalefaces/test/subject10.sad.gif'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxNNQ6-WM_Ld"
      },
      "source": [
        "image = Image.open(test_image).convert('L')\n",
        "image_np = np.array(image, 'uint8')\n",
        "image_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUGkF1Q4Ninp"
      },
      "source": [
        "image_np.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut_l-QSNNn7t"
      },
      "source": [
        "prediction = lbph_face_classifier.predict(image_np)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22XfWA6bOiox"
      },
      "source": [
        "prediction[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb9T5wF2N71g"
      },
      "source": [
        "expected_output = int(os.path.split(test_image)[1].split('.')[0].replace('subject', ''))\n",
        "expected_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcN3jt5UOUJ9"
      },
      "source": [
        "cv2.putText(image_np, 'Pred: ' + str(prediction[0]), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "cv2.putText(image_np, 'Exp: ' + str(expected_output), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "cv2_imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eyUv8l00oAt"
      },
      "source": [
        "### Evaluating the face classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJcCdWm7P33p"
      },
      "source": [
        "paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]\n",
        "predictions = []\n",
        "expected_outputs = []\n",
        "for path in paths:\n",
        "  #print(path)\n",
        "  image = Image.open(path).convert('L')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  prediction, _ = lbph_face_classifier.predict(image_np)\n",
        "  expected_output = int(os.path.split(path)[1].split('.')[0].replace('subject', '')) \n",
        "\n",
        "  predictions.append(prediction)\n",
        "  expected_outputs.append(expected_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n60u0NEEQ8kp"
      },
      "source": [
        "type(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOT1AMkhRBmV"
      },
      "source": [
        "predictions = np.array(predictions)\n",
        "expected_outputs = np.array(expected_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVlkm6hkRIrJ"
      },
      "source": [
        "type(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQgB2ScRLmx"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8PhkMhxRSDv"
      },
      "source": [
        "expected_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brDGncBPRjKf"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(expected_outputs, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srcIm3MrR5xb"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pywl22gASMPh"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(expected_outputs, predictions)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIModdwtSVm9"
      },
      "source": [
        "import seaborn\n",
        "seaborn.heatmap(cm, annot=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw1aTLB6SdP2"
      },
      "source": [
        "## Dlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7svnaxog97Ss"
      },
      "source": [
        "import dlib\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO_I5o6RKpFt"
      },
      "source": [
        "### Detecting facial points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYyZCTG8-Kxz"
      },
      "source": [
        "face_detector = dlib.get_frontal_face_detector()\n",
        "points_detector = dlib.shape_predictor('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Weights/shape_predictor_68_face_landmarks.dat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlywU7Y7_bsi"
      },
      "source": [
        "image = cv2.imread('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Images/people2.jpg')\n",
        "face_detection = face_detector(image, 1)\n",
        "for face in face_detection:\n",
        "  points = points_detector(image, face)\n",
        "  for point in points.parts():\n",
        "    cv2.circle(image, (point.x, point.y), 2, (0,255,0), 1)\n",
        "\n",
        "  #print(points.parts())\n",
        "  #print(len(points.parts()))\n",
        "\n",
        "  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
        "  cv2.rectangle(image, (l, t), (r, b), (0,255,255), 2)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhZ2dDNe54Oe"
      },
      "source": [
        "### Detecting facial descriptors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBunTbwvEbBD"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJBYZDULEjN4"
      },
      "source": [
        "# Resnet: https://arxiv.org/abs/1512.03385\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "points_detector = dlib.shape_predictor('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Weights/shape_predictor_68_face_landmarks.dat')\n",
        "face_descriptor_extractor = dlib.face_recognition_model_v1('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Weights/dlib_face_recognition_resnet_model_v1.dat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNqWwugGqQM"
      },
      "source": [
        "index = {}\n",
        "idx = 0\n",
        "face_descriptors = None\n",
        "\n",
        "paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]\n",
        "for path in paths:\n",
        "  #print(path)\n",
        "  image = Image.open(path).convert('RGB')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  face_detection = face_detector(image_np, 1)\n",
        "  for face in face_detection:\n",
        "    l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
        "    cv2.rectangle(image_np, (l, t), (r, b), (0, 0, 255), 2)\n",
        "\n",
        "    points = points_detector(image_np, face)\n",
        "    for point in points.parts():\n",
        "      cv2.circle(image_np, (point.x, point.y), 2, (0, 255, 0), 1)\n",
        "\n",
        "    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
        "    #print(type(face_descriptor))\n",
        "    #print(len(face_descriptor))\n",
        "    #print(face_descriptor)\n",
        "    face_descriptor = [f for f in face_descriptor]\n",
        "    #print(face_descriptor)\n",
        "    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
        "    #print(face_descriptor)\n",
        "    #print(face_descriptor.shape)\n",
        "    face_descriptor = face_descriptor[np.newaxis, :]\n",
        "    #print(face_descriptor.shape)\n",
        "    #print(face_descriptor)\n",
        "\n",
        "    if face_descriptors is None:\n",
        "      face_descriptors = face_descriptor\n",
        "    else:\n",
        "      face_descriptors = np.concatenate((face_descriptors, face_descriptor), axis = 0)\n",
        "\n",
        "    index[idx] = path\n",
        "    idx += 1\n",
        "  #cv2_imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF8Ed2izODzS"
      },
      "source": [
        "face_descriptors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynYHDQdwOarV"
      },
      "source": [
        "face_descriptors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MfqbVIVOhga"
      },
      "source": [
        "len(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsl-LZSBOrvc"
      },
      "source": [
        "index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLLaqtBb57EN"
      },
      "source": [
        "### Calculating the distance between faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A0R4JO2QcC6"
      },
      "source": [
        "face_descriptors[131]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx4-hF3yQNjK"
      },
      "source": [
        "# https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm\n",
        "np.linalg.norm(face_descriptors[131] - face_descriptors[131])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0WesKaXRG_f"
      },
      "source": [
        "np.linalg.norm(face_descriptors[131] - face_descriptors[130])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCfcrZWbRk_h"
      },
      "source": [
        "np.linalg.norm(face_descriptors[131] - face_descriptors[129])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf5XCjjtSAwy"
      },
      "source": [
        "np.linalg.norm(face_descriptors[131] - face_descriptors[128])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR71E6gdShBB"
      },
      "source": [
        "np.linalg.norm(face_descriptors[0] - face_descriptors, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pRuXBfS4yF"
      },
      "source": [
        "np.argmin(np.linalg.norm(face_descriptors[0] - face_descriptors[1:], axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH1ZwQKXTxLS"
      },
      "source": [
        "np.linalg.norm(face_descriptors[0] - face_descriptors[1:], axis = 1)[91]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_rUY0dO5-J0"
      },
      "source": [
        "### Detecting faces with Dlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-034wqtVHVz"
      },
      "source": [
        "threshold = 0.5\n",
        "predictions = []\n",
        "expected_outputs = []\n",
        "\n",
        "paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]\n",
        "for path in paths:\n",
        "  image = Image.open(path).convert('RGB')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  face_detection = face_detector(image_np, 1)\n",
        "  for face in face_detection:\n",
        "    points = points_detector(image_np, face)\n",
        "    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
        "    face_descriptor = [f for f in face_descriptor]\n",
        "    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
        "    face_descriptor = face_descriptor[np.newaxis, :]\n",
        "\n",
        "    distances = np.linalg.norm(face_descriptor - face_descriptors, axis = 1)\n",
        "    min_index = np.argmin(distances)\n",
        "    min_distance = distances[min_index]\n",
        "    if min_distance <= threshold:\n",
        "      name_pred = int(os.path.split(index[min_index])[1].split('.')[0].replace('subject', ''))\n",
        "    else:\n",
        "      name_pred = 'Not identified'\n",
        "\n",
        "    name_real = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))\n",
        "\n",
        "    predictions.append(name_pred)\n",
        "    expected_outputs.append(name_real)\n",
        "\n",
        "    cv2.putText(image_np, 'Pred: ' + str(name_pred), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "    cv2.putText(image_np, 'Exp : ' + str(name_real), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "\n",
        "\n",
        "  cv2_imshow(image_np)\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "expected_outputs = np.array(expected_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT-FE84fajb1"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPdfJRmQalKR"
      },
      "source": [
        "expected_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVdGI3xoatoE"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(expected_outputs, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_7ri5zj6Alb"
      },
      "source": [
        "## Homework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k4LA3AZbWd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNtcCZURbUhD"
      },
      "source": [
        "import zipfile\n",
        "path = '/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Datasets/jones_gabriel.zip'\n",
        "zip_object = zipfile.ZipFile(file=path, mode='r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBLCIuBNbY0S"
      },
      "source": [
        "def get_image_data():\n",
        "  paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]\n",
        "  faces = []\n",
        "  ids = []\n",
        "  for path in paths:\n",
        "    image = Image.open(path).convert('L')\n",
        "    image_np = np.array(image, 'uint8')\n",
        "    id = int(path.split('.')[1])\n",
        "    \n",
        "    ids.append(id)\n",
        "    faces.append(image_np)\n",
        "  \n",
        "  return np.array(ids), faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgoUfIboba2L"
      },
      "source": [
        "ids, faces = get_image_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm7Rm6dnbc7A"
      },
      "source": [
        "lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_classifier.train(faces, ids)\n",
        "lbph_classifier.write('lbph_classifier.yml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sQvshSRbfBl"
      },
      "source": [
        "lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_face_classifier.read('/content/lbph_classifier.yml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJMfLHRHbhBD"
      },
      "source": [
        "image = Image.open('/content/jones_gabriel/person.1.1.jpg')\n",
        "image.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgFA9zScblF3"
      },
      "source": [
        "paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]\n",
        "for path in paths:\n",
        "  image = Image.open(path).convert('L')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  prediction, _ = lbph_face_classifier.predict(image_np)\n",
        "  expected_output = int(path.split('.')[1])\n",
        "\n",
        "  cv2.putText(image_np, 'Pred: ' + str(prediction), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "  cv2.putText(image_np, 'Exp: ' + str(expected_output), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "  cv2_imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}